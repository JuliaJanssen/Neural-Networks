{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Author contributions\n",
    "Please fill out for each of the following parts who contributed to what:\n",
    "- Conceived ideas: \n",
    "- Performed math exercises: \n",
    "- Performed programming exercises:\n",
    "- Contributed to the overall final assignment: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4\n",
    "## Autoencoder\n",
    "\n",
    "    Hand-in bug-free (try \"Kernel\" > \"Restart & Run All\") and including all (textual as well as figural) output via Brightspace before the deadline (see Brightspace).\n",
    "    \n",
    "Learning goals:\n",
    "1. Derive and implement the mean-squared-error loss function and the rectified linear activation function\n",
    "1. Implement an autoencoder as a neural network with unsupervised learning\n",
    "1. Check what face features the autoencoder has learned to encode in the hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on the architecture\n",
    "\n",
    "The autoencoder network that you are about to implement has the same structure as in the MLP exercise: The input, hidden, and output node layers are connected with two weight layers. This time, the $n_h$ hidden layer nodes use a *rectified linear* activation function, and the output units use *linear* activations. \n",
    "\n",
    "Note that an autoencoder performs regresson, not to be confused with classification in the previous assignment. Also note that an autoencoder is nothing more than a multilayer perceptron, where the targets ($T$) are equal to the inputs ($X$). \n",
    "\n",
    "The data set is the Yale Face Database, which is a small set of grayscale photos of faces, each showing a different facial expression. The autoencoder will have as many input and output units as there are pixels. The hidden layer has far less units, as our goal is to learn a compressed representation of faces. The autoencoders job is \"learning to reconstruct\", that is, learning to reconstruct the face at the input units in the output units, after passing the information through the hidden units. Basically this means that `X` and `Y` are equal here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Mean squared error (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we want to predict pixel values we have a regression problem, and MSE is a convenient loss function for regression problems. MSE is large when the prediction is off, and near zero when the prediction is most similar to the target. The mean squared error (MSE) is given by:\n",
    "$$L = \\frac{1}{2N} \\sum^N_n \\sum^K_k (t^{(n)}_k - y^{(n)}_k)^2$$\n",
    "Here, $t^{(n)}_k$ is the target and $y^{(n)}_k$ the prediction of the $n$th data example and $k$th output unit. \n",
    "\n",
    "We need the derivative of the MSE with respect to $y$ to do gradient descent (i.e., backpropagation) to tweak the parameters (i.e., the weights) for regression. Derive the MSE with respect to $y$, i.e. derive $\\frac{\\partial L}{\\partial y}$. You can ignore the batch index $n$ (i.e., derive with $N = 1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1: \n",
    "\n",
    "$$L = \\frac{1}{2N} \\sum^N_n \\sum^K_k (t^{(n)}_k - y^{(n)}_k)^2$$\n",
    "$\\frac{\\partial}{\\partial y} = -$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: The rectified linear unit activation function (ReLU) (1 point)\n",
    "The rectified linear activation function is given by:\n",
    "$$f(a) = max(0, a)$$\n",
    "\n",
    "Obtain its derivative $\\frac{\\partial f}{\\partial a}$. \n",
    "\n",
    "Hint: It is a simple conditional expression (two cases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2:\n",
    "$\\frac{\\partial f}{\\partial a} =\n",
    "  \\begin{cases}\n",
    "    0       & \\quad \\text{if } a \\leq 0\\\\\n",
    "    1  & \\quad \\text{if } a > 0\n",
    "  \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: The forward pass (1 point)\n",
    "The network is defined as having two layers $W^1$ and $W^2$, where $W^1$ connects the input $x$ with the hidden layer $h$, and $W^2$ connects the hidden layer $h$ with the output layer $y$. For the hidden layer, we use rectified linear units with the activation function $f(a) = max(0, a)$. The output layer is just a linear layer (with the linear activation function $g(a) = a$). Write down the expressions for $a^1$, $h$, $a^2$, and $y$, where $a^1$ and $a^2$ are the activities of the hidden and output layer before passing them through the rectified linear and linear activations, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3:\n",
    "\\begin{eqnarray*}\n",
    "a^1 &=&  \\\\\n",
    "h &=& f(a^1) = max(0, a^1) \\\\\n",
    "a^2 &=&  \\\\\n",
    "y &=& g(a^2) = a^2\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Gradient of the last layer (1 point)\n",
    "To compute the partial derivatives on the weights $W^2$ of the last layer, we have to propagate from the error function back through the non-linearity to the weights. Derive the chain of partial derivatives to compute $\\frac{\\partial L}{\\partial W^2_{ij}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4\n",
    "$\\LaTeX$ here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Gradient of the first layer (1 point)\n",
    "To compute the partial derivatives on the weights $W^1$ of the first layer, we have to propagate the error even further down the network. Derive the chain of partial derivatives to compute $\\frac{\\partial L}{\\partial W^1_{ij}}$.\n",
    "\n",
    "Due do the derivative of the rectified linear activation, which is a conditional expression; you will end up with a conditional expression here too:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\frac{\\partial L}{\\partial W^1_{ij}} &=& \n",
    "\\begin{cases}\n",
    "    ?, & \\text{if } a^1 > 0 \\\\\n",
    "    ?, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 5\n",
    "$ \\frac{\\partial L}{\\partial W_{ij}^1} $$\\frac{\\partial L}{\\partial W^1_{ij}} = \\frac{\\partial L}{\\partial a^1_{i}} \\frac{\\partial a^1_{i}}{\\partial W^1_{ij}}$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W^1_{ij}} = (\\sum_{k} \\frac{\\partial L}{\\partial a_k^2} \\frac{\\partial a_k^2}{\\partial a_i^1}) \\frac{\\partial \\sum_k w^1_{ik} x_k}{\\partial W^1_{ij}}$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W^1_{ij}} = (\\sum_{k} \\partial_k^2 \\frac{\\partial a_k^2} {\\partial a_i^1} ) x_{j}$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W^1_{ij}} = \\delta_i^1 x_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Implementation (2.5 points)\n",
    "Now we can start implementing the autoencoder. Write the following functions:\n",
    "1. `mean_squared_error(Y, X)`: Computes the mean squared error. You need to sum over the pixel axis 0, and then mean  the result over the examples.\n",
    "1. `relu(A)`: Passes the activity `A` through the rectified linear unit. Use [`np.maximum`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.maximum.html) to compare each element of A to 0.\n",
    "1. `linear(X, W)`: Computes the activities `A` as `X` weighted by `W`. Just like in the previous exercises. \n",
    "1. `forward(X, W1, W2)`: Computes the forward pass for the two-layer AE with the `relu(A)` function at the hidden units. As the linear activation is just the trivial identity there is no activation function at the output units. Returns `A1`, `H` and `Y`. \n",
    "1. `backward(X, A1, H, Y, W2)`: Computes the backward pass for the two-layer AE with ReLU hidden units and MSE. The conditional can be realized by multiplying with the matrix `(A1 > 0).astype('float')`. \n",
    "1. `train_network(X_train, X_val, n_hidden, n_epochs, eta)`: Implement the training procedure (train the model on training data, and evaluate on both training and validation data). See the skeleton code for some help. Note that we have supplied a `initialize_weights(n_in, n_out)` function to initialize weights in the range from the MLP assignment. Remember that the input is equal to the output, so we do not need anything but `X_train` for training. \n",
    "\n",
    "Feel free to copy some code from the previous exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(n_in, n_out):\n",
    "    \"\"\"\n",
    "    Initializes a weight matrix.\n",
    "    INPUT:\n",
    "        n_in  = [int] number of input units.\n",
    "        n_out = [int] number of output units\n",
    "    OUTPUTS\n",
    "        W = [n_out n_in] the initial weight matrix\n",
    "    \"\"\"\n",
    "    r = np.sqrt(6) / np.sqrt(n_out + n_in)\n",
    "    return np.random.uniform(-r, r, [n_out, n_in])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(Y, X):\n",
    "    \"\"\"\n",
    "    Computes the mean squared error.\n",
    "    INPUT:\n",
    "        Y = [P N] output vector for N examples of length P\n",
    "        X = [P N] target vector for N examples of length P\n",
    "    OUTPUTS\n",
    "        L = [flt] the MSE\n",
    "    \"\"\"\n",
    "    ## Code here ##\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(A):\n",
    "    \"\"\"\n",
    "    Computes the rectified linear activation.\n",
    "    INPUT:\n",
    "        A = [K N] activity matrix of K units for N examples\n",
    "    OUTPUT\n",
    "        Y = [K N] output matrix of K units for N examples\n",
    "    \"\"\"\n",
    "    Y = np.zeros(len(A))\n",
    "    for i in range(0, len(A)):\n",
    "        Y[i] = max(0, A[i])\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(X, W):\n",
    "    \"\"\"\n",
    "    Computes the activities for a fully connected layer.\n",
    "    INPUT:\n",
    "        X = [P N] data matrix of P input units for N examples\n",
    "        W = [Q P] weight matrix of P inputs to Q outputs\n",
    "    OUTPUT\n",
    "        A = [Q N] activity matrix of Q output units for N examples\n",
    "    \"\"\"\n",
    "    A = []\n",
    "    \n",
    "    for w in W:\n",
    "        A.append(np.dot(X, w))\n",
    "        \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, W1, W2):\n",
    "    \"\"\"\n",
    "    Computes the forward pass for a two-layer AE with relu hidden units.\n",
    "    INPUT\n",
    "        X  = [P N] data matrix of P inputs for N examples\n",
    "        W1 = [Q P] weight matrix of the first layer from P input pixels to Q outputs\n",
    "        W2 = [P Q] weight vector of the second layer of Q inputs to P output pixels\n",
    "    OUTPUT\n",
    "        A1 = [Q N] activation matrix of Q hidden units for N examples\n",
    "        H  = [Q N] output matrix of Q hidden units for N examples\n",
    "        Y  = [P N] output pixel vectors (reconstructions) for N examples\n",
    "    \"\"\"    \n",
    "    ## Code here ##\n",
    "    return A1, H, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(X, A1, H, Y, W2):\n",
    "    \"\"\"\n",
    "    Computes the backward pass for a two-layer network with sigmoid and softmax units, and cross-entropy loss.  \n",
    "    INPUT:\n",
    "        X  = [P N] data matrix of P inputs for N examples\n",
    "        A1 = [Q N] activation matrix of Q hidden units for N examples\n",
    "        H  = [Q N] output matrix of Q hidden units for N examples\n",
    "        Y  = [P N] output pixel vectors of length P for N examples\n",
    "        W2 = [P Q] weight vector of the second layer of Q inputs to P outputs\n",
    "    OUTPUT\n",
    "        dW1 = [Q P] gradient matrix for the weights of layer 1 of P inputs to Q outputs\n",
    "        dW2 = [P Q] gradient matrix for the weights of layer 2 of Q inputs to P outputs\n",
    "    \"\"\"\n",
    "    dW1 =  * X\n",
    "    dW2 =  * Y\n",
    "    return dW1, dW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(X_train, X_val, n_hidden=30, n_epochs=2000, eta=10**-5):\n",
    "    \"\"\"\n",
    "    Performs the training procedure for a two-layer MLP with ReLU hidden units and MSE.\n",
    "    INPUT:\n",
    "        X_train  = [P N] training data matrix of P inputs for N training examples\n",
    "        X_val    = [P M] validation data matrix of P inputs for M validation examples\n",
    "        n_hidden = [int] number of hidden units (default 30)\n",
    "        n_epochs = [int] number of training epochs (default 2000)\n",
    "        eta      = [flt] learning rate (default 10^-5)\n",
    "    OUTPUT:\n",
    "        W1         = [Q P] the learned weights for layer 1 of P inputs to Q outputs\n",
    "        W2         = [P Q] the learned weights for layer 2 of Q inputs to P output pixels\n",
    "        train_loss = [Z 1] the training loss for Z epochs\n",
    "        val_loss   = [Z 1] the validation loss for Z epochs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize W1 and W2 (use initialize_weights())\n",
    "    W1 = initialize_weights(len(X_train), n_hidden)\n",
    "    W2 = initialize_weights(n_hidden, len(X_train))\n",
    "    \n",
    "    # Loop over epochs\n",
    "    train_loss = np.zeros((n_epochs))\n",
    "    val_loss = np.zeros((n_epochs))\n",
    "    for i_epoch in range(n_epochs):\n",
    "        \n",
    "        # Forward pass\n",
    "        A1_train, H_train, Y_train = forward(X_train, W1, W2)\n",
    "        A1_val, H_val, Y_val = forward(X_val, W1, W2)\n",
    "        \n",
    "        # Backward pass\n",
    "        dW1, dW2 = backward(X_train, A1, H, Y_train, W2)\n",
    "        \n",
    "        # Parameter update\n",
    "        W1 = W1 - eta * dW1 * X_train\n",
    "        W2 = W2 - eta * dW2 * Y_train\n",
    "        \n",
    "        # Save loss\n",
    "        train_loss[i_epoch] = mean_squared_error(Y_train, X_train)\n",
    "        val_loss[i_epoch] = mean_squared_error(Y_val, X_val)\n",
    "        \n",
    "        # Print progress and loss\n",
    "        if i_epoch % 50 == 0:\n",
    "            print(\"Epoch {}/{}. Train loss: {:.3f}. Validation loss: {:.3f}.\".format(\n",
    "                1+i_epoch, n_epochs, train_loss[i_epoch], val_loss[i_epoch]))\n",
    "        \n",
    "    return W1, W2, train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "In the next cells we load and prepare the face dataset. We also show example faces from the data set. Then we remove the mean from the data, and divide it by its standard deviation. This process, leading to a data set with zero-mean and unit variance is almost always an important preprocessing step. No information gets lost, but many common machine learning methods expect such *standardized* or *z-transformed* data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of face data set: (768, 165).\n"
     ]
    }
   ],
   "source": [
    "# Read dataset\n",
    "maxsz = [32, 32]\n",
    "X = []\n",
    "i = 0\n",
    "for file_name in os.listdir(os.path.join(os.getcwd(), \"yalefaces\")):\n",
    "    if file_name[:7] != \"subject\":\n",
    "        continue\n",
    "    im = Image.open(os.path.join(os.getcwd(), \"yalefaces\", file_name))\n",
    "    im.thumbnail(maxsz, Image.ANTIALIAS)\n",
    "    data = np.asarray(im)\n",
    "    if i == 0:\n",
    "        sz = data.shape\n",
    "    X.append(np.ndarray.flatten(data))\n",
    "    i += 1\n",
    "X = np.array(X).astype(\"float32\")\n",
    "X = X.T\n",
    "\n",
    "# Print dimensions\n",
    "print(\"Dimensions of face data set: {}.\".format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot some examples\n",
    "fig, ax = plt.subplots(2, 5, figsize=(12, 4))\n",
    "ax = ax.flatten()\n",
    "for i_example in range(len(ax)):\n",
    "    ax[i_example].imshow(X[:, i_example*10].reshape((sz)), cmap=\"gray\")\n",
    "    ax[i_example].set_xticks([], [])\n",
    "    ax[i_example].set_yticks([], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise data to zero mean and unit variance. We are doing this manually here as we need \n",
    "# mu and sigma to revert this operation (add mu, multiply by sigma) when \n",
    "# visualizing the resulting reconstructed faces. \n",
    "\n",
    "mu = X.mean(axis=1)\n",
    "sigma = X.std(axis=1)\n",
    "\n",
    "X -= np.expand_dims(mu, 1)\n",
    "X /= np.expand_dims(sigma, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions training inputs: (768, 100)\n",
      "Dimensions validation inputs: (768, 40)\n",
      "Dimensions testing inputs: (768, 25)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset in training, validation, and testing split\n",
    "X_train = X[:, :100]\n",
    "X_val = X[:, 100:140]\n",
    "X_test = X[:, 140:]\n",
    "\n",
    "# Print dimensions\n",
    "print(\"Dimensions training inputs: {}\".format(X_train.shape))\n",
    "print(\"Dimensions validation inputs: {}\".format(X_val.shape))\n",
    "print(\"Dimensions testing inputs: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: Running autoencoder training (0.5 points)\n",
    "Now that we have done all the work, we can finally run the autoencoder to learn reconstructing faces. \n",
    "\n",
    "1. Train your network on the training dataset `X_train`, and validate it at each epoch on the test set `X_val`. Use de default values for the number of hidden units, learning rate, and number of epochs.\n",
    "1. After training, plot the train and validation losses over epochs (as returned by `train_network()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network\n",
    "## Code here ##\n",
    "\n",
    "# Plot the training and validation losses\n",
    "## Code here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: Reconstruction (1 point)\n",
    "\n",
    "Choose 5 faces from the set, and plot their original and their reconstructed image side-by-side. That is, plot a chosen face and the output your trained autoencoder (represented by the weights) creates for it.\n",
    "\n",
    "Use [`np.reshape`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.reshape.html) to reshape pixel values for the input and output images to their original dimensions `sz` in a 2D array. Then make use of [`plt.imshow()`](https://matplotlib.org/devdocs/api/_as_gen/matplotlib.pyplot.imshow.html) with a `gray` colormap to show the faces. \n",
    "\n",
    "You need to revert the scaling operation by multiplying by `sigma` and adding the `mean` (both previously computed) on each `x` and `y` (If you don't, your real and reconstructed images will be off, e.g. too dark.). Think carefully about whether you have to do this before or after passing the images through your network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a 5-by-2 figure with plt.subplots\n",
    "## Code here ##\n",
    "\n",
    "# Loop over 5\n",
    "## Write code here ##\n",
    "\n",
    "    # Take a new example from X (the autoencoder input)\n",
    "    ## Code here ##\n",
    "    \n",
    "    # Forward pass of X through the network, obtain the reconstruction y\n",
    "    ## Code here ##\n",
    "    \n",
    "    # Plot the original X\n",
    "    ## Code here ##\n",
    "    \n",
    "    # Plot the reconstructed X (output Y)\n",
    "    ## Code here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise 9: Weights and receptive fields (1 point)\n",
    "We can visualize what was learned during classification and by the autoencoder. During training, the hidden units have become pattern detectors that you can interpret as *receptive fields*. \n",
    "\n",
    "You should visualize both `W1` and `W2`. To visualize the learned pattern of a single unit $i$, use [`np.reshape`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.reshape.html) to reshape the weights leading from all image pixels to unit $i$ into a 2D array. Then make use of [`plt.imshow()`](https://matplotlib.org/devdocs/api/_as_gen/matplotlib.pyplot.imshow.html) with a `gray` colormap to show the learned pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize W1\n",
    "## Code here ##\n",
    "\n",
    "# Visualize W2\n",
    "## Code here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
